---
title: "Effect of Campaign Spending (up to October 17) on Votes Received in 2018 House Midterms"
author: "Daniel Truver"
date: "11/26/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(dplyr)
library(ggplot2)
library(rjags)
library(mice)
library(stringr)
```

```{r final.clean}
load("full_data.Rdata")
na_2016 = is.na(full_data$prop_dem2016)
neg_2016 = full_data$prop_dem2016 < 0
neg_2018 = full_data$prop_dem2018 < 0
full_data$prop_dem2016[na_2016] = 0
full_data$prop_dem2016[neg_2016] = 1
full_data$prop_dem2018[neg_2018] = 1

none_forest = which(is.na(full_data$`Paid_employees_for_pay_period_including_March_12_Agriculture,_forestry,_fishing_and_hunting`))

none_extraction = which(is.na(full_data$`Paid_employees_for_pay_period_including_March_12_Mining,_quarrying,_and_oil_and_gas_extraction`))

none_util = which(is.na(full_data$Paid_employees_for_pay_period_including_March_12_Utilities))

full_data$`Paid_employees_for_pay_period_including_March_12_Agriculture,_forestry,_fishing_and_hunting`[none_forest] = 0
full_data$`Annual_payroll_($1,000)_Agriculture,_forestry,_fishing_and_hunting`[none_forest] = 0

full_data$`Paid_employees_for_pay_period_including_March_12_Mining,_quarrying,_and_oil_and_gas_extraction`[none_extraction] = 0
full_data$`Annual_payroll_($1,000)_Mining,_quarrying,_and_oil_and_gas_extraction`[none_extraction] = 0

full_data$Paid_employees_for_pay_period_including_March_12_Utilities[none_util] = 0
full_data$`Annual_payroll_($1,000)_Utilities`[none_util] = 0

no_hisp = which(is.na(full_data$Hispanic_or_Latino_and_Race_Mexican))
no_hisp_cols = 37:40
full_data[no_hisp, no_hisp_cols] = 0
noGross = which(str_detect(names(full_data), "Gross_Rent"))
to_remove_gross = noGross[-9]
full_data = full_data[,-to_remove_gross]
full_data = full_data %>%
  filter(dist != "AZ_02")
```

#### Introduction and Purpose

All files required to reproduce this analysis with the same or updated data are here: https://github.com/truverdj/Election-Inference-2018  

Does money affect elections? Intuitively, yes. The magnitude of the effect is our concern here. We will build a dose-response curve for 2018 Democratic midterm campaigns for the US House of Representatives. Our "dose" is campaign spending. Our "response" is proportion of votes received. We will take into account demographics and other aspects of each Congressional district as covariates in a generalized propensity score model.  

#### Data

The data on campaign spending comes from Federal Election Commission (FEC) [filings of each campaign](https://www.fec.gov/data/advanced/?tab=candidates). This data also includes information on Incumbent, Challenger, and Open seat designations. Because the FEC does not update in real time, the data used in this analysis is for campaign spending up to October 17, 2018. So, our treatment is campaign spending up to this date. Thankfully, this methodology is entirely reproducible. Using an updated FEC file requires minimal code changes. 

Election results are from the Associated Press and retrieved via the [New York Times](https://www.nytimes.com/interactive/2018/11/06/us/elections/results-house-elections.html). The FEC will eventually have these results as well, but as of the time of this analysis, they do not. A definitive analysis will use the certified vote tallies of each district.

Background characteristics of the congressional districts come from the American Community Survey (ACS) conducted by the [census bureau](https://www.census.gov/mycd/). See "List of District Covariates" section at the end for list of variables used in the model. 

Not all 435 districts are in this set. Reasons for exclusion include: no Democratic party campaign in the district, campaigns that did not have data up to the October 17 deadline (the FEC will force them to comply eventually), and Arizona district 2 because the .csv file on it looks like this 

!["AZ-02 Data Missing"](AZexcluded.png){width=40%}

At the end of all filtering, we have 393 districts with which to work.

```{r jags_data}
unique_states = unique(full_data$Cand_Office_St)
state_num = seq_along(unique_states)
state_index = unlist(lapply(full_data$Cand_Office_St, function(st){
  which(unique_states == st)
}))
full_data$state_index = state_index
lm_form = as.formula("log(Total_Disbursement)~.-Cand_Office_St-dist-
                     prop_dem2018-dems-1-state_index")
y = log(full_data$Total_Disbursement)
X = model.matrix(lm_form, full_data)
n = nrow(X)
p = ncol(X)
jags_list = list(y = y, X = X, p = p, n = n, state_index = state_index)
```

#### Generalized Propensity Score

We want to specify and random effects model with a different effect for each state. For each Democratic campaign $i$, let $s(i)$ denote the state in which the campaign took place. Let $W_i$ be the total campaign spending up to October 17, 2018. We will use $\alpha_{s(i)}$ to denote the random effects of each campaign's state and $\beta$ as expected for the regression coefficients. We denote the noise as $\epsilon$. Then our full model is:

$$
\begin{aligned}
\log(W_i) &= \alpha_{s(i)} + \beta X_i + \epsilon\\
\alpha_s &\sim N(\beta_\alpha, \sigma_\alpha^2) \\
\beta_\alpha &\sim N(0,10^4) \\
\sigma_\alpha &\sim Unif(0,100) \\
\beta &\sim N(0, 10^4) \\
\epsilon &\sim N(0, \sigma^2) \\
\sigma &\sim Unif(0,100) 
\end{aligned}
$$

And here is the model in JAGS.

```{r, echo=TRUE}
model = "model{
  for(i in 1:length(y)){
    y[i] ~ dnorm(mu[i], tau)
    mu[i] = alpha[state_index[i]] + inprod(beta[],X[i,])
  }
  for(j in 1:48){
    alpha[j] ~ dnorm(beta_alpha, tau_alpha)
  }
  
  
  beta_alpha ~ dnorm(0,1/10000)
  sigma_alpha ~ dunif(0,100)
  tau_alpha = 1/(sigma_alpha * sigma_alpha)
  
  for(k in 1:p){
    beta[k] ~ dnorm(0, 1/10000)
  }
  
  sigma ~ dunif(0, 100)
  tau = 1/(sigma * sigma)
}"
params = c("beta","beta_alpha", "alpha", "sigma", "sigma_alpha")
n_burn = 1000
n_iter = 15000
n_chains = 2
```

A better way to think about how this is in terms of its multivariate normal interpretation. 

$$
\log(\vec{W}) \sim MVN(\vec{\beta_\alpha} + X\beta, \Sigma)
$$

Where $\Sigma$ is of the form:
```{r, cache=TRUE}
disp_mat = matrix(0, nrow = 393, ncol = 393)
fill_from = 1
for(s in unique(state_index)){
  numcells = sum(s == state_index)
  fill_to = numcells + fill_from - 1
  fill = matrix(1, nrow = numcells, ncol = numcells)
  disp_mat[fill_from:fill_to,fill_from:fill_to] = fill
  fill_from = fill_from + numcells
}
for(i in 1:196){
  wastop = disp_mat[i,]
  wasbot = disp_mat[393-i,]
  disp_mat[i,] = wasbot
  disp_mat[393-i,] = wastop
}
SparseM::image(disp_mat, col = c("white", "black"))
```

The shaded cells are the non-zero entries of the covariance matrix. The blocks along the diagonals are states. Units within a state correlate with each other and share information. Units in different states do not. This is meant to account for the natural clustering of campaigns by state. 

We have a total of 207 covariates from the ACS and FEC. Such a large dimension reduction to the GPS is unfortunate, but alternatives are scarce. 

```{r the_big_one}
if(!file.exists("jags_samp.Rdata")){
  m = jags.model(textConnection(model), data = jags_list,
              n.chains = n_chains)
  update(m, n.iter = n_burn)
  jags_samp = coda.samples(m,n.iter = n_iter, variable.names = params)
  save(jags_samp,file = "jags_samp.Rdata")
} else {
  load("jags_samp.Rdata")
}
```

```{r extract_jag}
post = as.data.frame(jags_samp[[1]])
alpha_names = paste0("alpha_", 1:48)
beta_names = paste0("beta_",1:207)
other_names = c("beta_alpha", "sigma", "sigma_alpha")
post_names = c(alpha_names, beta_names, other_names)
names(post) = post_names
post_estimates = apply(post, 2, mean)
alphas = post_estimates[str_detect(names(post_estimates), "alpha_")]
betas = post_estimates[str_detect(names(post_estimates), "beta_\\d")]
sigma = post_estimates["sigma"]
sigma_alpha = post_estimates["sigma_alpha"]
sigma_z.2 = sigma^2 + sigma_alpha^2
```

```{r}
mu_z = X %*% betas + alphas[state_index]
gps = dnorm(y, mean = mu_z, sd = sqrt(sigma_z.2))
full_data$gps = gps
```

```{r}
log_disb = log(full_data$Total_Disbursement)
quant_disb = quantile(log_disb, 0.2*(0:5))
quant_disb[1] = 0
quant_label = unlist(lapply(log_disb, function(x){
  t = rep(NA, length(quant_disb)-1)
  for(i in 2:length(quant_disb)){
    t[i-1] = quant_disb[i-1] < x & x <= quant_disb[i]
  }
  which(t)
}))
full_data$quant_label = quant_label
g = list()
for(i in sort(unique(quant_label))){
  Quantile = paste0("W quantile ", i)
  gi = geom_density(data = full_data %>% filter(quant_label == i),
                    aes(x = gps, color = i))
  g[[i]] = gi
}
g_overlap = ggplot() +
  geom_density(data = full_data %>% filter(quant_label == 1),
                    aes(x = gps, color = "W quantile 0-20%")) +
  geom_density(data = full_data %>% filter(quant_label == 2),
                    aes(x = gps, color = "W quantile 20-40%")) +
  geom_density(data = full_data %>% filter(quant_label == 3),
                    aes(x = gps, color = "W quantile 40-60%")) +
  geom_density(data = full_data %>% filter(quant_label == 4),
                    aes(x = gps, color = "W quantile 60-80%")) +
  geom_density(data = full_data %>% filter(quant_label == 5),
                    aes(x = gps, color = "W quantile 80-100%")) +
  ggtitle("GPS Overlap, 5 Quantiles") +
  theme_bw()
```

##### Overlap

To check overlap, we broke spending down into its 5 20% quantiles. The plot of GPS for each quantile is below. 

```{r}
g_overlap
```

We see that overlap is good amongst the middle 3 quantiles and also between the upper and lower quantiles. Overall overlap is decent until the GPS drops below 0.1. 

```{r, message=FALSE, warning=FALSE}
new_data = full_data
names(new_data) = str_remove_all(names(new_data), ",|\\$|'|\\(|\\)")
x_to_check = names(new_data)[-c(1,2,4,6,7,210:212)] 
models = lapply(seq_along(x_to_check), function(i){
  f = x_to_check[[i]]
  if(!i %in% 1:2){
    Y = new_data[,f]
    X = new_data[,c("Total_Disbursement", "gps")]
    t = cbind(Y, X)
    mod0 = lm(Y~Total_Disbursement + gps, data = t)
    mod_summ = summary(mod0)
    p_value = mod_summ$coefficients["Total_Disbursement", 4]
  } else if(i == 1) {
    Y = new_data[,f] == "OPEN"
    X = new_data[,c("Total_Disbursement", "gps")]
    t = cbind(Y, X)
    mod0 = glm(Y~Total_Disbursement + gps, data = t, family = binomial())
    mod_summ = summary(mod0)
    p_value = mod_summ$coefficients["Total_Disbursement", 4]
  } else {
    Y = new_data[,f]
    X = new_data[,c("Total_Disbursement", "gps")]
    t = cbind(Y, X)
    mod0 = glm(Y~Total_Disbursement + gps, data = t, family = binomial())
    mod_summ = summary(mod0)
    p_value = mod_summ$coefficients["Total_Disbursement", 4]
  }
  p_value
})
p_vals = unlist(models)
g_balance = ggplot(data = data.frame(p_vals)) +
  geom_density(aes(x = p_vals)) +
  geom_vline(xintercept = 0.05, color = "red") +
  ggtitle("Balance by P-value") +
  xlab("Significance") +
  theme_bw()
bad_balance = which(p_vals < 0.05) 
trouble_vars = x_to_check[bad_balance]
wellbehaved_vars = x_to_check[-bad_balance]
# unblanced: house value, poverty, higher education, type of industry (tech), payroll of industry (which are highly correlated), health insurance
# also incumbents cannot be balanced
# balanced: industry(agriculture, health care, retail), race, sex, age, lower education
```

Next, we check balance by fitting the model $X \sim W + GPS$ for each covariate $X$. We check the significance on the coefficient of $W$ and plot the density of the p-values.

```{r}
g_balance
```

The red line is 0.05. As we can see, there are some balance issues. Digging into the data, we can see which covariates are causing problems. Some unbalanced variables are those related to health insurance coverage, educational attainment, property value, poverty, and share of the economy held by the tech industry. A political scientist may note that all of these are correlated. On the other hand, race, sex, age, and share of agriculture/retail industry are balanced. This is a weakness of the GPS model. Many of the covariates correlate with each other, so imbalance in one implies imbalance in the others. 

```{r}
dose_data = full_data %>% 
  select(prop_dem2018, Total_Disbursement, gps)
names(dose_data) = c("Y", "W", "r")
dose_data$Y[dose_data$Y == 1] = .99
y = qnorm(dose_data$Y)
dose_matrix = matrix(NA, nrow = nrow(dose_data), ncol = 6)
dose_matrix[,1] = 1
dose_matrix[,2] = log(dose_data$W)
dose_matrix[,3] = log(dose_data$W)^2
dose_matrix[,4] = dose_data$r
dose_matrix[,5] = dose_data$r^2
dose_matrix[,6] = log(dose_data$W) * dose_data$r
X = dose_matrix
n = nrow(X)
p = ncol(X)
jags_list = list(y = y, X = X, p = p, n = n)
```

#### Dose-Response Curve

We fit the dose-response curve according to the following model. Let $Y_i$ denote the proportion of the vote obtained by the candidate of campaign $i$ with covariates $X_i$ and GPS $R_i$. $\Phi$ denotes the cdf of the standard normal.

$$
E\left[ \Phi^{-1}(Y_i) \mid W_i, R_i \right] = \alpha_0 + \alpha_1W_i + \alpha_2W_i^2 + \alpha_3R_i + \alpha_3R_i^2 + \alpha_5W_iR_i
$$

We fit it as a regression in JAGS.

```{r, echo=TRUE}
model = "model{
  for(i in 1:length(y)){
    y[i] ~ dnorm(mu[i], tau)
    mu[i] = inprod(beta[],X[i,])
  }
  
  for(k in 1:p){
    beta[k] ~ dnorm(0, 1/10000)
  }
  
  sigma ~ dunif(0, 100)
  tau = 1/(sigma * sigma)
}"
params = c("beta", "sigma")
n_burn = 1000
n_iter = 15000
```

```{r}
if(!file.exists("dose_samp.Rdata")){
  m = jags.model(textConnection(model), data = jags_list,
              n.chains = 1)
  update(m, n.iter = n_burn)
  dose_samp = coda.samples(m,n.iter = n_iter, variable.names = params)
  save(dose_samp,file = "dose_samp.Rdata")
} else {
  load("dose_samp.Rdata")
}
```

```{r}
BETA = dose_samp[[1]]
betas = apply(BETA, 2, mean)[1:6]
sigma = apply(BETA, 2, mean)[7]
BETAs = BETA[10*(1:1500),1:6]
dose_response = lapply(log(dose_data$W), function(w){
  dose_matrix = matrix(NA, nrow = nrow(dose_data), ncol = 6)
  dose_matrix[,1] = 1
  dose_matrix[,2] = w
  dose_matrix[,3] = w^2
  dose_matrix[,4] = dose_data$r
  dose_matrix[,5] = dose_data$r^2
  dose_matrix[,6] = w * dose_data$r
  responses = dose_matrix %*% betas
  response_point = mean(responses)
  response_point
})
trt = log(dose_data$W)
trt.fin = trt[order(trt)]
res = unlist(dose_response)
res.fin = res[order(trt)]
trt.original = exp(trt.fin)
res.original = pnorm(res.fin)
log_dose_response = data.frame(res = res.original, trt = trt.fin)
dose_response.df = data.frame(res = res.original, trt = trt.original)
```

```{r, cache=TRUE}
dose_response = lapply(log(dose_data$W), function(w){
  dose_matrix = matrix(NA, nrow = nrow(dose_data), ncol = 6)
  dose_matrix[,1] = 1
  dose_matrix[,2] = w
  dose_matrix[,3] = w^2
  dose_matrix[,4] = dose_data$r
  dose_matrix[,5] = dose_data$r^2
  dose_matrix[,6] = w * dose_data$r
  responses = dose_matrix %*% t(BETAs)
  response_points = apply(responses, 2, mean)
  range(response_points)
})
```

```{r}
min_res = unlist(lapply(dose_response, function(r){r[1]}))
min_res.fin = min_res[order(trt)]
max_res = unlist(lapply(dose_response, function(r){r[2]}))
max_res.fin = max_res[order(trt)]
dose_response.df$min = pnorm(min_res.fin)
dose_response.df$max = pnorm(max_res.fin)
curve_changepoint = dose_response.df$trt[min(which(dose_response.df$res > 0.5))]
upper_changepoint = dose_response.df$trt[min(which(dose_response.df$max > 0.5))]
lower_changepoint = dose_response.df$trt[min(which(dose_response.df$min > 0.5))]
log_curve = ggplot(data = dose_response.df) +
  geom_line(aes(x = log(trt), y = res)) +
  geom_point(aes(x = log(trt), y = res), pch = 16) +
  geom_ribbon(aes(ymin = min, ymax = max, x = log(trt), fill = "Uncertainty"), 
              alpha = 0.3) +
  geom_vline(xintercept = log(curve_changepoint), color = "red", lty = "dotted") +
  geom_vline(xintercept = log(lower_changepoint), color = "red", lty = "dotted") +
  geom_vline(xintercept = log(upper_changepoint), color = "red", lty = "dotted") +
  geom_hline(yintercept =  0.50, color = "blue", lty = "dotted") +
  # ylim(0,1) + 
  # xlim(0,17) +
  ylab("Proportion of Vote") +
  xlab("Log(Campaign Spending)") +
  ggtitle("Dose-Response Curve") +
  theme_bw()
ori_curve = ggplot(data = dose_response.df) +
  geom_line(aes(x = trt, y = res)) +
  geom_point(aes(x = trt, y = res), pch = 16) +
  geom_ribbon(aes(ymin = min, ymax = max, x = trt, fill = "Uncertainty"), 
              alpha = 0.3) +
  # ylim(0,1) + 
  ylab("Proportion of Vote") +
  xlab("Campaign Spending") +
  ggtitle("Dose-Response Curve") +
  theme_bw()
```

The observed dose-response curve is:

```{r}
log_curve
```

The measures of uncertainty in the curve come from posterior draws of the outcome model coefficients. 

#### Future Work

First and foremost, I would like to learn to conduct a sensitivity analysis on projects of this type. Then there is clearly the opportunity to use updated FEC data and certified vote counts in the analysis to determine how spending throughout the entire campaign affected the outcome. The FEC will get around to posting this data in their own good time, but at least we know it's coming. Loss to follow-up is not an option for campaigns. Lastly, I would like to take some measure of gerrymandering into account. Gerrymandering is not binary (gerrymandered for, gerrymandered against, not gerrymandered), so it would require some expert advice.

#### Curve not on Log Scale

```{r}
ori_curve = ggplot(data = dose_response.df) +
  geom_line(aes(x = trt, y = res)) +
  geom_point(aes(x = trt, y = res), pch = 16) +
  geom_ribbon(aes(ymin = min, ymax = max, x = trt, fill = "Uncertainty"), 
              alpha = 0.3) +
  ylab("Proportion of Vote") +
  xlab("Campaign Spending") +
  ggtitle("Dose-Response Curve") +
  theme_bw()
ori_curve
```

#### List of District Covariates

```{r}
load("census_districts.Rdata")
pres = new_states[[1]]
pres1 = pres[,1:2]
knitr::kable(pres1)
```

<!--
models of correlation: http://www2.stat.duke.edu/~cr173/Sta444_Sp18/

JAGS gods: http://www.flutterbys.com.au/stats/tut/tut7.3b.html
--->