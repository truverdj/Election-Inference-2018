---
title: "Candidate Data"
author: "Daniel Truver"
date: "11/23/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(dplyr)
library(stringr)
library(rvest)
```

```{r}
if(!file.exists("nyt_calls.Rdata")){
  page = read_html("https://www.nytimes.com/interactive/2018/11/06/us/elections/results-house-elections.html")
table1 = page %>%
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div[3]/div[2]/div[1]/table") %>%
  html_table()
table2 = page %>%
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div[3]/div[2]/div[2]/table") %>%
  html_table()
table3 = page %>% 
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div[3]/div[2]/div[3]/table") %>%
  html_table()
table4 = page %>%
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div[3]/div[2]/div[4]/table") %>%
  html_table()
table5 = page %>%
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div[3]/div[2]/div[5]/table") %>%
  html_table()
nyt_calls = rbind(table1, table2, table3, table4, table5)
save(nyt_calls, file = "nyt_calls.Rdata")
} else {
  load("nyt_calls.Rdata")
}
```


```{r usable_names}
clean_nyt = function(df){
  nyt_calls = df
for(i in 1:ncol(nyt_calls)){
  nyt_calls[,i] = str_remove_all(nyt_calls[,i], "%")
}
for(i in 2:ncol(nyt_calls)){
  t = nyt_calls[,i]
  t_new = unlist(lapply(t, function(x){
    ifelse(x == "Unc.", -1, as.numeric(str_remove(x, "%"))/100)
  }))
  nyt_calls[,i] = t_new
}
district = nyt_calls$District
dis_letter = str_extract(district, "\\D+")
dis_atLarge = !str_detect(district, "\\d")
dis_num = str_extract(district, "\\d+")
dis_num[is.na(dis_num)] = ".At.Large"
dis_num[!str_detect(dis_num, "\\d\\d")] = paste0("0",dis_num[!str_detect(dis_num, "\\d\\d")])
dis_st_pre = tolower(str_remove_all(dis_letter, "\\.|\\s"))
dis_st = unlist(lapply(dis_st_pre, function(ch){
  if(ch == "ala"){"alab"} 
  else if (ch == "wva"){"wv"}
  else if (ch == "fla"){"fl"}
  else if (ch == "kan"){"ks"}
  else if (ch == "miss"){"ms"}
  else if (ch == "mont"){"mt"}
  else {ch}
}))
st_test_ab = tolower(state.abb)
st_test_fu = tolower(state.name)
t = lapply(1:435, function(i){
  totest = dis_st[i]
  test_ab = which(str_detect(st_test_ab, totest))
  if(length(test_ab) > 0){
    test_ab
  } else {
    test_fu = which(str_detect(st_test_fu, totest))
    test_fu
  }
})
dis_ab = state.abb[unlist(t)]
nyt_calls$State = dis_ab
nyt_calls$Num = dis_num
return(nyt_calls)
}
new_nyt_calls = clean_nyt(df = nyt_calls)
new_nyt_calls = new_nyt_calls[order(new_nyt_calls$State),] %>%
  mutate(Num = str_replace(Num, ".At.Large", "0"))
```

```{r}
if(!file.exists("nyt_calls2016.Rdata")){
  page2 = read_html("https://www.nytimes.com/elections/2016/results/house")
table1 = page2 %>%
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div/div[2]/div[1]/table") %>%
  html_table()
table2 = page2 %>%
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div/div[2]/div[2]/table") %>%
  html_table()
table3 = page2 %>% 
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div/div[2]/div[3]/table") %>%
  html_table()
table4 = page2 %>%
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div/div[2]/div[4]/table") %>%
  html_table()
table5 = page2 %>%
  html_node(xpath = "//*[@id=\"eln-election-page\"]/div/div[5]/div/div[2]/div[5]/table") %>%
  html_table()
nyt_calls2016 = rbind(table1, table2, table3, table4, table5)
save(nyt_calls2016, file = "nyt_calls2016.Rdata")
} else {
  load("nyt_calls2016.Rdata")
}
new_nyt_calls2016 = clean_nyt(df = nyt_calls2016)
```

```{r}
cand = read.csv("cand_2018.csv", stringsAsFactors = FALSE)
house = cand %>%
  filter(Cand_Office == "H") %>%
  select(-Link_Image) %>%
  mutate(Cand_Name = tolower(Cand_Name)) 
house = house[order(house$Cand_Office_St),]
house_mod = house %>%
  filter(Total_Disbursement > 0) %>%
  mutate(Coverage_End_Date = as.Date(Coverage_End_Date, "%m/%d/%Y")) %>%
  select(Cand_Name, Cand_Id, Cand_Office_St, Cand_Office_Dist, Cand_Party_Affiliation,
         Cand_Incumbent_Challenger_Open_Seat, Total_Disbursement, Coverage_End_Date)
save(house_mod, file = "house_mod.Rdata")
```

```{r}
if(!file.exists("peeps.Rdata")){
wiki_page = read_html("https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2018#Alabama")
test_xpath = paste0("//*[@id=\"mw-content-text\"]/div/table[",1:50+12,"]")
test = lapply(test_xpath, function(x_path){
  wiki_page %>%
    html_node(xpath = x_path) %>%
    html_table(fill = TRUE)
})
names(test) = state.abb
peeps = test
save(peeps, file = "peeps.Rdata")
} else {
  load("peeps.Rdata")
}
```

```{r}
peeps[["PA"]] = peeps[["PA"]][-c(4,19),]
new_peeps = lapply(state.abb, function(st){
# for (st in state.abb){
t = peeps[[st]]
t = t[-1,]
if(nrow(t) == 1){
  t[1,1] = str_replace(t[1,1], "at-large", "0")
}
names(t)[2] = "district_numbers"
names(t)[3] = "incumbent_name"
names(t)[4] = "incumbent_party"
t_names = t$Candidates
t_first = str_extract(t_names, "^(.+?)\\[")
t_second = str_extract(t_names, "\\].+\\[")
t_first_let = str_remove_all(t_first, "[^a-zA-Z\\s]+")
t_second_let = str_remove_all(t_second, "[^a-zA-Z\\s]+")
t$cand1 = t_first_let
t$cand2 = t_second_let
t = t %>% select(District, cand1, cand2)
t$num = str_extract(t$District, "\\d+")
t$District = str_remove_all(t$District, "\\s\\d+")
names(t)[1] = "state"
abbr = state.abb[which(str_detect(t$state[1], state.name))]
single_digit = which(str_detect(t$num, "^\\d$"))
t$num[single_digit] = paste0("0", t$num[single_digit])
rownames(t) = paste(abbr, t$num, sep = "_")
t = t %>% select(-state, -num)
dems1 = which(str_detect(t$cand1, "Democratic"))
dems2 = which(str_detect(t$cand2, "Democratic"))
tofill = rep(NA, nrow(t))
tofill[-c(dems1, dems2)] = "none"
tofill[dems1] = str_remove(t$cand1[dems1], "Democratic")
tofill[dems2] = str_remove(t$cand2[dems2], "Democratic")
t$dems = tofill
t$uncon = str_detect(t$dems, "Unopposed")
t$dems = str_remove(t$dems, "Unopposed")
t = t[,c("dems", "uncon")]
t
# }
})
names(new_peeps) = state.abb
save(new_peeps, file = "new_peeps.Rdata")
```

```{r nyt_scrape_names}
url_states = tolower(state.name) %>%
  str_replace(.,"\\s","-")
names(url_states) = state.abb
# nyt_pages = list()
nyt_peeps = list()
# for(st in url_states){
#   nyt_url = paste0("https://www.nytimes.com/interactive/2018/11/06/us/elections/results-",
#                  st,"-elections.html")
#   page_nyt = read_html(nyt_url)
#   nyt_pages[[st]] = page_nyt
#   # tab1 = page_nyt %>%
#   #   html_node(xpath = "//*[@id=\"house-group\"]/table") %>%
#   #   html_table(fill = TRUE)
#   # nyt_peeps[[st]] = tab1
#   Sys.sleep(1)
# }
# save(nyt_pages, file = "nyt_pages.Rdata")
for(st in state.abb){
  nyt_peeps[[st]] = st
}
names(nyt_pages) = state.abb
at_larges = new_nyt_calls$State[which(new_nyt_calls$Num == "00")]
for(st in state.abb){
  if(!st %in% at_larges){
    nyt_peeps[[st]] = nyt_pages[[st]] %>% 
      html_node(xpath = "//*[@id=\"house-group\"]/table") %>% 
      html_table(fill = TRUE)
  }
}
nyt_peeps$AK = nyt_pages$AK %>% 
  html_node(xpath = "//*[@id=\"ak-2015-2018-11-06-results-table-container\"]/table") %>%
  html_table(fill = TRUE)
```

```{r, echo=FALSE, eval=FALSE}
# this block runs everything else in markdown
```